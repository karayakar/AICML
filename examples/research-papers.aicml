PAGE:
  id: research-dossier-2025
  title: Applied AI Research Papers — 2025 Focus
  owner: lab-insights
  type: research-dossier
  lang: en

META:
  name: compiled-by
  value: Atlas Research Collective

META:
  name: focus
  value: Multi-modal reasoning + efficient fine-tuning

SECTION:
  id: intro
  level: 1

TITLE:
  Why These Papers Matter

P:
  This set captures practical advances in retrieval-augmented generation, safety alignment,
  and efficient adapters for vertical deployments. Each study links to open implementations
  and benchmarks against strong baselines.

SECTION:
  id: highlights
  level: 1
  order: 2

TITLE:
  Key Takeaways

LIST:
  style: unordered

ITEM:
  Retrieval routers now outperform static chain-of-thought prompts by 9–14 F1 points on structured QA.

ITEM:
  Safety-alignment distillation keeps smaller student models within 2% of teacher guardrail coverage.

ITEM:
  LoRA + domain adapters cut fine-tuning tokens by ~63% for legal and medical corpora.

DICT:
  id: dict.paper.v1
  kind: paper
  field.i: paper_id
  field.t: title
  field.a: authors
  field.v: venue
  field.to: topic_cluster
  field.y: year
  field.l: url
  field.m: headline_metric
  field.n: summary

SET:
  id: papers-2025
  dict: dict.paper.v1
  kind: research

ROW:
  i: P-2025-RA-G
  t: Routing-Augmented Generators for Structured Knowledge Bases
  a: H. Duran; M. Patel; S. Green
  v: ACL 2025
  to: Retrieval + RAG
  y: 2025
  l: https://arxiv.org/abs/2504.01234
  m: +12.8 F1 vs CoT
  n: Mixture-of-experts router selects evidence-specific generation heads.

ROW:
  i: P-2025-SAFE-DISTILL
  t: Guardrail Distillation for Lightweight Agents
  a: L. Adebayo; K. Sato
  v: NeurIPS 2025
  to: Safety Alignment
  y: 2025
  l: https://arxiv.org/abs/2506.04567
  m: 98% policy parity
  n: Student policy inherits teacher refusals with low compute overhead.

ROW:
  i: P-2025-LORA-ADAPT
  t: Sparse LoRA Adapters for Regulated Domains
  a: C. Salim; R. Ortega; J. Wu
  v: ICML 2025
  to: Efficient Fine-Tuning
  y: 2025
  l: https://arxiv.org/abs/2502.07890
  m: -63% tokens vs full FT
  n: Layer-wise sparsity plus domain heads keep accuracy within 1.4%.

ROW:
  i: P-2025-MED-VQA
  t: Cross-Modal VQA for Radiology Workflows
  a: N. Li; P. Alvarez
  v: MICCAI 2025
  to: Vision-Language
  y: 2025
  l: https://arxiv.org/abs/2503.03122
  m: +8.3 BLEU vs baseline
  n: Combines report priors with pathology-aware adapters.

ENTITY:
  id: leaderboard
  kind: leaderboard
  description: Aggregated benchmark signals for highlighted papers.
  metric.token_savings_pct: 40
  metric.safety_coverage_pct: 96
  metric.rag_gain_f1: 12
  metric.adapter_efficiency_pct: 63

QUERY:
  id: q.topic-cluster
  from.set: papers-2025
  using.dict: dict.paper.v1
  select: topic,count(id)
  group: topic

QUERY:
  id: q.venues
  from.set: papers-2025
  using.dict: dict.paper.v1
  select: venue,count(id)
  group: venue
  sort: count(id) desc
